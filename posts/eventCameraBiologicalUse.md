# Biological-Ecological Research using Event Camera
January-22-2025

---
This article is an English translation of a review originally written for submission to an information science journal in Japanese, with assistance from ChatGPT. For further reference, please see a separate article compiling a list of studies utilizing event cameras in biological research.

If you are interested in applying event cameras to biological research, feel free to reach out via the email address below.


# Introduction
When mankind makes new discoveries, they are often accompanied by advances in instrumentation. The spatio-temporal domains that we can learn about have increased through the use of measurement instruments, such as observing distant stars that cannot be seen with the human eye through telescopes and measuring sounds with wavelengths higher than ultrasonic waves that cannot be heard with the human ear through microphones.
Furthermore, recent developments in machine learning technology, such as deep learning, have not only expanded the spatio-temporal space that can be measured, but have also made it possible for machines to perform tasks such as classification and segmentation without our interpretation (visualization) of the measured data. This evolution in a different direction has led to an increased focus on sensors that have been difficult to utilize with conventional technologies. Event cameras have attracted particular attention in recent years. Event cameras are one type of neuromorphic device based on information transmission by nerves. It has a completely different data format and representation from existing frame-based cameras, and can coexist with temporal resolution and dark performance that are unattainable with conventional frame-based technologies. On the other hand, there are limitations that must be understood by the measurer.
We have used event cameras to capture images of marine life, particles, and a variety of other organisms, including bats at night. This paper details how this event camera could revolutionize the field of biological observation.

# History of the biological measurement by the imaging system  
The history of attempts to record visual information is a long one. Early examples include humans depicting wild animals in cave paintings \cite{brumm2021oldest} and Haeckel, equipped with a microscope, producing beautiful illustrations of microscopic marine organisms \cite{bhl182319}. In the 19th century, the advent of photography greatly enhanced techniques for recording spatial information, and this development was constantly accompanied by eye-catching photographs of living creatures. In 1839, the shadow of a plant was directly recorded on photosensitive paper \cite{talbot_album_1839}, a technique dubbed “photogenic drawing.” Subsequently, this recording technology stabilized into a method that captured the light passing through a camera obscura’s lens, leading to the publication of many photographs of nature and organisms from the 19th to the 20th century. The invention of the flash in the 1890s considerably broadened the possibilities of photography. Nighttime images of white-tailed deer were captured by an automated system in which the animal itself triggered the shutter \cite{L.1906}, and in the 1920s, the light of magnesium flares enabled the first color recording of fish swimming naturally underwater \cite{longley1927life}.

Around the same period, technology for capturing high-speed phenomena also evolved. As early as 1870, sequences of galloping horses were already being photographed by using multiple cameras, and fast mechanical shutters made it possible to record continuous motion onto a single strip of film \cite{braun1992picturing}. Stroboscopic technology, developed by Edgerton, enabled extremely short exposures that could not be achieved with mechanical shutters alone, thereby capturing even faster movements such as flying insects and bullets \cite{edgerton1939flash}. This technology significantly contributed to research on the flight of insects \cite{chadwick1939simple,reed1942frequency}. Once film became widely available, photography was popularized; it was later swept into the wave of digitalization, and by the 2000s, anyone could record high-quality photographs and videos on a personal device. Biologists now capture the instantaneous behaviors of organisms under the microscope, while ecologists carry out long-term automatic observations at remote locations through the power of sunlight and the internet \cite{Yasuda2002,swann2011evaluating}. As photographic technology has advanced, biological measurement using images has expanded from descriptive, phenomenon-based approaches to more analytical ones. Moreover, it is increasingly treated as just one among many large datasets—without relying on human interpretation—especially in fields where deep learning is employed.

In this era, we must once again reconsider the “limitations of biological research using imaging technology.” Living organisms keep their activities day and night. Deep-sea creatures thrive in environments with little to no light. Furthermore, many species, from birds to plants, possess organs optimized for high-speed functionality. In measurements using imaging, capturing objects in darkness or those moving at high speeds is particularly challenging.

Measurements in low-light conditions are typically achieved using strobe lights, infrared imaging, or specially designed high-sensitivity cameras, while high-speed objects are captured using high-speed cameras. However, when it comes to “measuring high-speed motion occurring in low-light conditions,” the difficulty rises significantly. Moreover, maintaining a stable power supply in extreme environments such as oceans, mountains, or forests further complicates measurements using existing technologies.

# What is Event Camera?
Event cameras are a type of neuromorphic device that record the spatio-temporal information of light. They are different from conventional cameras in that they record only the changes in light intensity, not the entire image. Each pixel in the sensor independently determines whether to output data, and the output is transferred as a continuous, unsynchronized stream. If the brightnesschange is positive, it is assigned a positive polarity; if negative, it is assigned a negative polarity. This means that the data recorded by event cameras is not a single image, but a series of events that occur at specific times and locations.
The brightness change, referred to as an “event,” is represented as a time-series dataset consisting of four values: coordinates x, y, polarity, and timestamp. This structure is sparse and unsynchronized, unlike conventional frame-based data. Because synchronization across all pixels is not required, individual pixels can output data continuously at an equivalent rate of 10,000 fps. Furthermore, since data from static objects without brightness changes is not recorded, the camera is highly efficient in terms of power consumption and memory usage.

A notable characteristic of event cameras is their high dynamic range. Incident light is first converted into current by photodiodes and then into voltage. During this process, logarithmic compression is applied, enabling the output of events even with small brightness changes under low-light conditions. This capability allows the camera to capture events effectively regardless of temporal and spatial changes in both high-illumination and low-illumination environments.

Nevertheless, event cameras uniquely combine low-light performance and high-speed capabilities while minimizing resource usage such as power and storage. As a result, research utilizing event cameras is rapidly increasing \cite{chakravarthi2024recent,gallego2020event,Iddrisu2024survey}. In the field of biology, their application is still in its early stages, much like other technologies that have emerged in the past (Figure 1).

# Current Utilization of Event Cameras and Applications in industrial fields

For any sensor, it is necessary to represent the acquired data in a format that can be interpreted and analyzed. In the case of event data, attempts have been made to frame events by projecting them onto a plane within a certain time range, allowing the use of well-developed image processing techniques designed for frame-based cameras \cite{kogler2009bio}. While this approach has the advantage of leveraging existing analysis methods \cite{gallego2020event,hamann2024mousesis}, it fails to fully utilize the high temporal resolution and event frequency, which are characteristic of event cameras.

To address these challenges, new representation methods that preserve the sparsity and asynchrony of event data while enabling high-speed processing are being researched. For instance, techniques have been proposed to model events as spatiotemporal graphs and process them using Graph Neural Networks (GNNs) \cite{schaefer2022aegnn,Gehrig2022PushingTL,9010397,9879077,9710541,GNNDenoise}. Additionally, efforts to incorporate Spiking Neural Networks (SNNs) have been explored \cite{9892618,8100264,SpikeMS,osswald2017spiking,stromatias2017event,yao2021temporal,camunas2019low,aydin2024hybrid,stagsted2020towards,Kaiser2016,orchard2013Spike,Barbier2021spike,Zhu2022SpikeReconstruction}.

These new processing methods particularly shine in applications where the high temporal resolution and low power consumption of event cameras can be fully utilized. For example, integrating event cameras as the “eyes” of autonomous driving systems and advanced driver-assistance systems (ADAS) is expected to address issues faced by conventional frame-based cameras \cite{Shariff2024Automotive}. Traditional frame-based cameras can capture high-resolution and color information, but they struggle with rapid brightness changes, detecting fast-approaching objects, and ensuring visibility in nighttime or adverse weather conditions. In contrast, event cameras demonstrate superior performance in these scenarios \cite{gehrig2024low}.

Moreover, combining event cameras with Spiking Neural Networks (SNNs), another event-driven neuromorphic computing approach, allows for significantly lower power consumption compared to traditional Deep Neural Networks (DNNs). Although still in its early stages, including methods for training models, this field is expected to advance further.

A particularly notable application of the high-speed capabilities of event cameras is vibration analysis and optical acoustic measurement techniques. Continuous vibration monitoring has long been required to detect early signs of critical issues such as wear, misalignment, and imbalance in machinery \cite{chaudhury2014vibration}. Consequently, vibration measurement is actively conducted in the manufacturing sector using methods such as direct measurement with accelerometers and laser Doppler vibrometers, as well as monitoring vibration-induced sound and heat \cite{randall2021vibration,Ghazali2021Vibration}. The high-speed performance and ability of event cameras to ignore stationary background information make them ideal for efficiently capturing fine vibrations. Several techniques have been proposed in conjunction with noise reduction methods, and it has been demonstrated that this approach achieves performance comparable to expensive laser Doppler vibrometers \cite{Shi2023Vibration,na2023Vibration,Baldini2024}.

Similarly, the ability to digitize subtle vibrations has shown that event cameras can replicate the functionality of the optical acoustic measurement method known as Visual Microphone, previously reliant on expensive high-speed cameras \cite{visualMicrophone}. Specific analyses of guitar strings and speaker diaphragms have been reported, demonstrating not only the reconstruction of sounds originating from vibrating objects but also spatial sound reconstruction. This application, traditionally requiring high-cost high-speed cameras, can now be achieved with significantly reduced costs through event cameras, greatly expanding its potential applications \cite{Niwa_2023_CVPR,Shirakawa2023}.

Another noteworthy application of event cameras is privacy-conscious activity monitoring in hospitals and care facilities. Event cameras, capable of functioning in low-light environments, can digitize the movements of individuals on beds or in hallways, regardless of time of day, thus helping reduce the operational burden on facility staff \cite{coram2025}. This application leverages the fact that event cameras do not record color or brightness information, thus contributing to privacy protection. However, brightness changes are recorded as event frequencies, making some degree of information reconstruction possible \cite{7780471,8954323,Fox_2024_WACV,9093366,Zhu2022SpikeReconstruction}. Therefore, like conventional cameras, careful consideration of privacy concerns is necessary for the use of event cameras.

# Biological Observation using Event Cameras

The challenges of conventional imaging technologies in biological measurements, as discussed earlier, can be addressed effectively by event cameras, which offer unique features. In recent years, applications of event cameras in the field of biology have begun to emerge, starting with cellular biology and gradually expanding into other areas.

This section aims to highlight four key reasons why biologists might find event cameras appealing: 1: high-speed performance, 2: low-light capability, 3: low power consumption and efficient storage, and 4: the ability to cancel motion blur. By presenting practical examples, this section provides information that can aid in the selection and application of event cameras for biological research.

## High-Speed Performance

Event cameras, often advertised as capable of achieving an equivalent of 10,000 fps, require careful consideration when capturing slow-moving objects. Due to the low frequency of event generation in such cases, applications like Particle Image Velocimetry (PIV) using tracer particles may encounter challenges, necessitating solutions such as the use of pulsed lasers \cite{EBIV:2022,PulsedEBIV:2023}. Therefore, if conventional high-speed cameras are available, they might be more suitable for such environments.

An effective example of event cameras in biological research is the analysis of periodic movements in organisms.

Takatsuka et al. proposed a method to analyze periodic biological movements using a two-step clustering approach similar to stream clustering. This method captures events representing the target object and performs frequency analysis to examine motion \cite{millisecond}. They defined 21 biologically relevant parameters and successfully classified zooplankton and protozoa, primarily using frequency information. Additionally, the study utilized infrared light as an observational light source to minimize the impact on marine organisms, including zooplankton. This research highlights the integration of event cameras’ high-speed capabilities with the unique requirements of observing biological phenomena in the marine environment.

## Low-Light Capability
Biological measurements in darkness, such as in nocturnal forests or caves, are expected to benefit greatly from event cameras. Observing the behavior of organisms in the wild provides a unique opportunity to study their natural behavior and uncover their ecology within the natural environment. However, unlike controlled indoor experiments, field experiments face long-standing challenges such as fluctuating light levels and weather-dependent conditions, making stable, long-term observations difficult. Specifically, measuring biological behavior in darkness requires lighting with carefully controlled intensity and frequency that does not disturb the organisms, further restricting experimental setups. While infrared or thermal cameras have traditionally been used for these purposes, their time resolution is inversely related to exposure time, making it difficult to capture fine details of organismal movements.

Event cameras, which can capture movement even under low-light conditions and visualize only moving objects, act as biological pass filters in nighttime field studies. For instance, in observing bats flying in darkness, moving objects are typically limited to bats and their prey, such as insects. Both need to be tracked with a high signal-to-noise (S/N) ratio. Event cameras simplify tracking in such challenging scenes, enabling automatic calculation of features such as the distance between predator and prey or flight characteristics (Figure).

That said, if the sole purpose is to capture biological activity in low-light conditions, extending the exposure time of frame cameras or using infrared or thermal cameras may suffice. Event cameras are particularly advantageous when conventional cameras are unsuitable. In the case of bats, for example, event cameras are ideal due to their ability to capture the high-speed flight of bats and their prey, which may not be visible on thermal cameras.

Additionally, event cameras’ high dynamic range makes them advantageous for observations that need to be conducted both day and night. The “eventPenguin” project used an event camera by inivation to observe penguins’ ‘ecstatic display’ even in low-light conditions \cite{10658483,hamann2024fourier}. Although limitations remain, such as separating head movements from other behaviors, the ability to process data consistently in both day and night settings offers significant advantages for nature-focused use cases.

Another promising application lies in visualizing particles within microfluidic devices—something high-sensitivity frame cameras cannot achieve. High-speed cameras paired with powerful lighting are typically required to track fast-moving particles, significantly limiting accessibility and scope \cite{D0LC00556H}. Event cameras, with their low-light capabilities, enable the capture of fast particles without the need for intense lighting, making them an ideal tool when additional information like particle color or brightness is of lesser importance. Similarly, for microscopic observations of biological particles such as phytoplankton, zooplankton, sperm cells, or other cells, light often becomes a major constraint in behavior analysis. The low-light performance of event cameras presents a significant breakthrough for biological observations, both in field and laboratory settings.

## Low Power Consumption and Efficient Storage
When the high-speed and low-light capabilities of event cameras are combined with their low power consumption and low storage requirements, their full potential is realized.

One of the most compelling use cases for event cameras in biological measurement is capturing fast movements in unpredictable scenarios. Since event cameras only output data when brightness changes occur, they maintain low power and storage consumption during periods of inactivity.

For example, observing flower-visiting insects often requires long-term, fixed-point monitoring, making it an ideal application for event cameras. In natural environments, storage and power supply are often limited. A system has been reported where event cameras act as triggers for frame cameras, reducing power and data usage while capturing appropriate images \cite{gebauer2024towards}. While infrared sensors are typically used as triggers for larger organisms, they are unsuitable for insects. As a result, periodic imaging systems, such as those capturing frames every few seconds, have been proposed \cite{nagai2022periodically}. By using event cameras as triggers, it becomes possible to capture images “when needed” and “at the necessary spatial and temporal resolution.” Although the system mentioned above uses the Event Vision System (EVS) solely as a trigger, combining it with methods that directly analyze event data could be particularly useful for studying insects, such as bees, that form communities and communicate through movement. A significant challenge, however, is managing background noise, such as swaying vegetation or rippling water, which requires appropriate noise reduction techniques.

Additionally, recording neural activity in biological systems often demands cameras capable of detecting subtle changes in light intensity at sampling rates ranging from 10 Hz to 1 kHz. While high-frame-rate, low-noise CMOS sensors are commonly used for this purpose, these sensors produce large amounts of data, making them unsuitable for long-term recording. In this context, event cameras, which combine high-speed performance, low power consumption, relatively low data rates, and high dynamic range, present an ideal solution \cite{8325076}.

## Cancel Motion Blur

Leveraging the sparse nature of event data is expected to make significant contributions to environmental monitoring for both industrial and academic purposes in marine settings.

Unlike terrestrial imaging, which is unaffected under clear conditions, underwater environments are always filled with particles, and the impact of suspended matter is particularly significant in coastal areas. Consequently, the removal of dynamic noise and accurate edge extraction of objects are critical challenges in marine sensing. Dynamic noise also poses problems in terrestrial settings, manifesting as rain or snow in images, which creates significant challenges for applications such as autonomous driving and infrastructure inspection. While deep learning techniques have been explored for noise removal in these scenarios \cite{zhang2024efficient}, recent studies have begun integrating event data \cite{zou2023seeing,bi2024rgb}. The sparse nature of event data enables edge extraction of moving objects without temporal compression, allowing for the separation of static and dynamic backgrounds at low computational costs. This approach is expected to see widespread adoption in marine environmental sensing.

With the recent miniaturization of cameras, their use as sensors for biologging has increased. By attaching small cameras to animals, researchers can gain insights into their predation behaviors and habitats. Such information can also be utilized for environmental monitoring \cite{渡辺伸一2023biologging}, enabling the collection of dynamic trajectory data of organisms, which was previously limited to Eulerian observations or Lagrangian observations using flow-following sensors. However, capturing images in low-light conditions can result in situations where objects are not visible or appear blurred due to limited shutter speed. Event cameras, by eliminating motion blur in such scenarios, could expand the scope of observation to include small particles like marine snow and plankton.

The ocean contains particles ranging in size from micrometers to tens of meters. These particles move through the marine space as a result of interactions driven by biological, chemical, and physical processes, facilitating the transport of various substances. Accurate acquisition of particle size distribution (PSD) is therefore essential. For smaller particles, observational methods based on conventional imaging are prone to significant errors due to the combined effects of limited pixel resolution and motion blur. Event cameras, with their high-speed capabilities, preserve the edges of moving objects and eliminate motion blur during particle imaging, enabling the capture of “high-contrast” particle data at the optical resolution limit.

We are currently conducting research and development to establish observational techniques for marine particles using this approach within moored systems.

# Conclusion
Event cameras are paving the way for new observational domains that were challenging or impossible to achieve with conventional measurement technologies. For event cameras to be widely adopted in biological observation, it is crucial to establish a community-driven framework for research and development involving both manufacturers and researchers.

Open-source processing software tailored to event data is essential. In traditional image processing, OpenCV has become the de facto standard. However, no equivalent package exists for event data, leaving researchers to implement their own processing algorithms. While some foundational tools, such as the Event Vision Library and neuromorphic drivers, have been developed by individual researchers \cite{eventVisionLibrary,neuromorphicDrivers}, they remain rudimentary.

In application-driven fields like biology, processing needs are often highly specific. Popular software packages such as ImageJ and DeepLabCut \cite{Mathisetal2018} are widely used due to their user-friendly GUI, extensibility, and broad applicability. For instance, DeepLabCut supports 3D tracking using data from multiple cameras \cite{nath2019using,joska2021acinoset}. While Prophesee’s Metavision software has introduced 3D reconstruction capabilities in its latest version, its usability for non-expert users remains limited.

Developing easy-to-use packages for event data processing is a critical first step to expanding the use of event cameras in fields like ecology. evsCluster, an analysis software currently being developed in collaboration with Sony Group Corporation, aims to facilitate biological analysis using event data. Its features include tracking, extraction of biologically significant features, and deep learning based on extracted features. For example, it enables the calculation of periodic movements, such as wingbeats or flagellar motion, as frequencies.

Making such software widely accessible and usable will be indispensable for advancing the application of event cameras in biological research.

By exploring the application of event cameras in extreme environments, such as deep-sea and polar regions, the use cases introduced in this paper can be expanded further. This opens up the possibility of redefining biology from a new perspective, leveraging event cameras as a transformative imaging technology.